-*- mode:org; -*-
file://~/org/agenda.org

* 開発環境
  :ENVIRONMENT:
  :STYLE: テスト駆動オブジェクト指向（TDD&OOD）
  :LANGUAGE: python
  :VIRTUALENV: pyenv + venv
  :TECH: object-oriented, dataclasses, requests, beautifulsoup, collection, jupyter-lab
  :END:

* 課題事項
*** DONE ソースがSVGだったらMyScriptを利用してLaTeX記法に変換できる。（画像のラベルセットへの置換）
   :LOGBOOK:
   - State "DONE"       from "TODO"       [2023-09-08 金 12:54]
   :END:
*** DONE LaTeXコマンドをパースするのは多分簡単
   :LOGBOOK:
   - State "DONE"       from "TODO"       [2023-09-08 金 12:54]
   :END:
*** TORACK 数学記法の形態素解析がうまく実装できなかったときの保険的代替案を考えておく。
**** 数学記法の形態素解析
どの単位で一単語とするのかが数学記法の場合明確でない。形態素解析の考え方を深く知り、もしかしたらオリジナルの形態素解析用パーサを作らないといけないかもしれない。

** TOTELL 質問事項
*** 9/22まで
*** 設計について
crawler+fastapiと、react
**** データベースはjsonで管理している。
RDB

**** TODO 同一サーバーでcrawlerデーモンとfastapiサーバーを動かして、１つのデータベースを共有することができるか

*** 今後の展望
**** chex.reacterでグラフ描画を実現



* TDDの流れ
1. 失敗するテストを書く（ほしい挙動をリストする）
2. テストを実行して失敗することを確認
3. テストを成功させる最低限の実装を書く（クソコードでもいいからテストを通過させる）
4. テストを実行して成功することを確認
5. テストがオチないようにしながら実装をリファクタリングする

** 格言１
はじめから複雑な世界を想像するよりは、まずはとても単純な世界を仮定して始めて、うまく行かなかったら複雑化させれたほうが良い。
*** 注釈
- とても単純な世界だと思ってやってみることのフットワークは軽くなくてはならない。
- どうやって複雑化させるのが良いのかはまた別の話。
** 格言２
ゼロからいきなり最良を実現するよりは、最低限のものを最良へ向けて改良していくほうが簡単だ。
** オリジナル要素
*** Jupyter Lab でSKETCHを書きながら世界のことを眺めてテストの設計を考えることは良いことでは？
*** テストを Jupyter Lab で書いちゃってもいいしね。

* OODについて
オブジェクトが担う責任と、オブジェクトの持つデータと職能は切り分けて考えなければならない。

オブジェクトの担う責任の仕様は、オブジェクトと外との相互作用のレイヤに基づいて決められるべきで、
保持するべきデータと持つべき職能の仕様は、オブジェクトが果たすべき責任に基づいて決められるべきだ。

また、
オブジェクトの担う責任の実行は、職能とデータの適切な時間的・空間的アサインと制御によって実現され、
職能の実行は、それ単独、もしくは必要なデータを引数として受け取ることのみに依存して実現されるべきだ。

以上のことから、次のことが分かる。
果たされるべき責任や振る舞いはオブジェクトのデータと職能に基づいて/依存して実行されるべきだ。つまり、責任や振る舞いの中で職能がコールされるべきだ。したがって、責任や振る舞いは、職能が実装されていることを前提として実行される。
一方でお互いの職能は自然に可能な限りに於いて、職能の実装を前提とせず、引数を介してその存在を前提とするべきだ。こうすることによりコールスタックが過度に深くなることを避け、また責任や振る舞いとは職能とデータの適切な時間的アサインによって実現するという自然なパラダイムをソースの上で自然に実現することができる。

では実際に、責任と職能の定義をどうやってするのか？それがデザインパターンや設計理論の領域である。

ポイントは、流動性をカプセル化すること、そして適切なカプセル化のために適切な責任の分割を行うこと。
責任はなるだけ不変的なものであるべきだ。この不変性への要求は、対象とする問題の本質的な構造の不変性への信仰に起因している。
ある種の問題の普遍的で本質的な構造を捉え、抽出することができたなら、それはほとんど変わることが無いはずだ。
これは一種の妥当な仮定であり、また信仰でもある。

# そのために”くりこみ”のラインを見極める。外界との相互作用と独立した内部処理。

** Crawlerの場合
crawlerの責任は、自動でクローリングすることとサイトマップを作ること。

そのために必要な遂行能力は、
- サイトをランダムウォークできること。
- 必要な情報を保存・読み出し・保存できること

これらの情報から、動作フローを考えることができる。
処理の場合分け（極めて詳細な責任や振る舞いに相当するもの）などは実装の段階で行えば良い。設計の段階でこのような委細まで責任や振る舞いに含めて考えられるのは熟達した設計者のみだ。


* 設計
README.orgに記述

* CRAWLER
設計の段に於いては、以下の４つの項目を順に下に降りていく。このときに、OODの概念が非常に有用。
実装の段に於いては、下から上に積み重ねていく。このとき、TDDの手法が火を吹く。

* CRAWLERの責任
*** 適切に初期化できる
*** 自動で対象ドメインを探索できる 
*** 過去の記録を探して読み出せる
*** 現在の探索結果を使って過去の記録を上書きして保存できる

* CRAWLERの動作フロー [0/4]
まずは、考えた責任に基づいて動作フローを考えることができる。
** TODO Crawler [0%]
*** TODO Crawler初期化 [0%]
**** TOTEST domainを渡して初期化
     :LOGBOOK:
     - State "TOTEST"     from              [2023-08-28 月 06:48]
     :END:
**** TOTEST indexを初期化する
     :LOGBOOK:
     - State "TOTEST"     from              [2023-08-28 月 06:48]
     :END:
**** TOTEST self._parent, self._target, self.footprintの初期化
     :LOGBOOK:
     - State "TOTEST"     from              [2023-08-31 木 11:29]
     :END:
***** TOTEST indexが空であればLPから始める
     :LOGBOOK:
     - State "TOTEST"     from              [2023-08-28 月 06:54]
     :END:
***** TOTEST indexがあればfootprintのスタート位置をランダムにindexから選ぶ
     :LOGBOOK:
     - State "TOTEST"     from              [2023-08-28 月 06:53]
     :END:

*** TODO 基礎的な振る舞い [0%]
**** self._parent.data.hrefsの更新
**** TOTEST self._parent.data.hrefsからtarget_hrefを選び、self._target_hrefに格納
     :LOGBOOK:
     - State "TOTEST"     from              [2023-08-28 月 06:57]
     :END:
***** TOTEST hrefsの中から特定のアルゴリズムにしたがって次のページを決める（最初は乱数）
     :LOGBOOK:
     - State "TOTEST"     from              [2023-08-28 月 06:59]
     :END:
**** TOTEST self._target_href.urlにリクエストを飛ばして、resを取得、self._resに保存
     :LOGBOOK:
     - State "TOTEST"     from              [2023-08-31 木 11:14]
     :END:
**** TOTEST resの結果に応じてself._target_hrefを更新、適切なresが得られるまで繰り返す
     :LOGBOOK:
     - State "TOTEST"     from              [2023-08-31 木 11:17]
     :END:
***** TOTEST 成功してればactive:True,self._target_href["n_passed"]+1,lastタイムスタンプ
      :LOGBOOK:
      - State "TOTEST"     from              [2023-08-31 木 15:10]
      :END:
***** TOTEST getに失敗すればactive:Falseにしてtarget_hrefの選定に戻ってやり直す
     :LOGBOOK:
     - State "TOTEST"     from              [2023-08-28 月 07:02]
     :END:



**** self._targetの作成
**** TOTEST indexからself._target_href.urlと同じurlをもったdataを取ってきてself._dataに格納
     :LOGBOOK:
     - State "TOTEST"     from              [2023-08-31 木 11:13]
     :END:
***** TOTEST このときのindexをself._iに格納する
      :LOGBOOK:
      - State "TOTEST"     from              [2023-08-31 木 11:23]
      :END:
***** TOTEST ヒットするdataがなければself._iは-1、self._dataはNone
      :LOGBOOK:
      - State "TOTEST"     from              [2023-08-31 木 11:46]
      :END:
**** TOTEST self._dataとself._resからSiteオブジェクトを作成し、self._targetに格納
     :LOGBOOK:
     - State "TOTEST"     from              [2023-08-31 木 11:14]
     :END:
***** self._data == None ならばself._resからdataも作成する。


**** self._target.dataの更新
**** TOTEST self._target.dataのパラメータを更新する
     :LOGBOOK:
     - State "TOTEST"     from "TOTEST"     [2023-08-31 木 11:56]
     :END:
***** self._target.data["n_visited"]+1
***** active:True
***** last timestamp
***** 
**** WAIT self._targetとself._parentの比較処理でself._target_href["score"]を計算
     :LOGBOOK:
     - State "WAIT"       from "TOTEST"     [2023-09-05 火 14:06] \\
       crawlerではこの処理は行わない。別のクラスのオブジェクトが担う
     - State "TOTEST"     from              [2023-08-31 木 14:58]
     :END:



**** self.indexとself.footprintの更新
**** TOTEST self.index[self._p_i]にself._parent.dataを格納
     :LOGBOOK:
     - State "TOTEST"     from              [2023-08-31 木 14:54]
     :END:
**** TOTEST self.index[self._i]にself._target.dataを格納
     :LOGBOOK:
     - State "TOTEST"     from              [2023-08-31 木 14:54]
     :END:
***** TOTEST self._i==-1であればインデックスにdataが存在しないページなのでindex.append
      :LOGBOOK:
      - State "TOTEST"     from              [2023-08-31 木 15:13]
      :END:

**** TOTEST self._targetをself._parentに格納
     :LOGBOOK:
     - State "TOTEST"     from              [2023-08-31 木 14:59]
     :END:
**** TOTEST self._iをself._p_iに格納
     :LOGBOOK:
     - State "TOTEST"     from              [2023-08-31 木 14:59]
     :END:
**** TOTEST self.footprintにself._target.dataを格納
     :LOGBOOK:
     - State "TOTEST"     from              [2023-08-31 木 15:15]
     :END:

*** TODO サイクル単位で情報を保存する [0%]
**** TOTEST footprintが初期化規定に触れたか判定
     :LOGBOOK:
     - State "TOTEST"     from              [2023-08-28 月 07:06]
     :END:
***** スタート地点に戻ってきた。
***** 一定以上の長さになった。
**** TOTEST 触れていたらcycle.jsonに書き出してfootprintは初期化
     :LOGBOOK:
     - State "TOTEST"     from              [2023-08-28 月 07:07]
     :END:
**** TOTEST 触れていたらindexも上書き保存
     :LOGBOOK:
     - State "TOTEST"     from              [2023-08-28 月 07:08]
     :END:
***** jsonに変換してからindex.jsonにダンプしないと行けない

*** TOTEST HTMLをjsonに保存できる
    :LOGBOOK:
    - State "TOTEST"     from              [2023-08-23 水 15:07]
    :END:
*** TOTEST HTMLからマークアップを削除して記事情報だけを抽出できる
    :LOGBOOK:
    - State "TOTEST"     from              [2023-08-23 水 15:08]
    :END:
*** TOTEST 記事情報を保存できる
    :LOGBOOK:
    - State "TOTEST"     from              [2023-08-23 水 15:09]
    :END:
*** TOTEST 記事情報からLaTeX記法を抽出できる
    :LOGBOOK:
    - State "TOTEST"     from              [2023-08-23 水 15:04]
    :END:
*** TOTEST LaTeX記法のみをまとめて保存できる
    :LOGBOOK:
    - State "TOTEST"     from "WAIT"       [2023-08-23 水 15:09]
    :END:
** TODO Webページ構造インデックス作成・表示機能（OFFICER） [0%]
*** 

** TODO 外部ストレージへの保存 [0%]
*** TOTEST S3へのログイン
    :LOGBOOK:
    - State "TOTEST"     from              [2023-08-23 水 15:13]
    :END:
*** TOTEST S3へのアップロード
    :LOGBOOK:
    - State "TOTEST"     from              [2023-08-23 水 15:11]
    :END:
*** TOTEST S3からのファイル取得
    :LOGBOOK:
    - State "TOTEST"     from              [2023-08-23 水 15:11]
    :END:
*** TOTEST 直接S3へソースを保存
    :LOGBOOK:
    - State "TOTEST"     from              [2023-08-23 水 15:12]
    :END:
** TODO デーモン化 [0%]
*** TOTEST リモートサーバ上で稼働することを確認
    :LOGBOOK:
    - State "TOTEST"     from              [2023-08-23 水 15:15]
    :END:
*** TOTEST 更新指示で対象サイトを訪問してソースの更新をする
    :LOGBOOK:
    - State "TOTEST"     from              [2023-08-23 水 15:16]
    :END:
*** TOTEST 定期的に対象サイトを訪問してソースの更新をする
    :LOGBOOK:
    - State "TOTEST"     from              [2023-08-23 水 15:17]
    :END:

* CRAWLERのデータと職能
責任に基づいて動作フローが描けたならば、その動作フローを実現するための職能が必要になり、この要請にしたがって職能を考えることができる。職能にとって重要なことは汎用性・独立性である。
** データ
*** domain
*** dir_name
*** index
*** _target
*** _parent
*** footprint

** 職能
*** TOTEST get_res
   :LOGBOOK:
   - State "TOTEST"     from              [2023-09-06 水 13:29]
   :END:
指定したURLからリクエストを引っ張ってこれる
*** TOTEST get_data_and_contents
   :LOGBOOK:
   - State "TOTEST"     from              [2023-09-06 水 13:40]
   :END:
responseからSiteDataとContentsを作れる
*** TOTEST select_target_href
   :LOGBOOK:
   - State "TOTEST"     from              [2023-09-06 水 13:51]
   :END:
次のターゲットを決められる
*** TOTEST select_data
   :LOGBOOK:
   - State "TOTEST"     from              [2023-09-06 水 13:54]
   :END:
現在のターゲットの情報がindexにあるかどうかを調べ、存在していたらデータを読み出せる。
*** TOTEST update_target
   :LOGBOOK:
   - State "TOTEST"     from              [2023-09-06 水 13:52]
   :END:
手元にある情報をもとにindexを更新できる
*** TOTEST load_index
   :LOGBOOK:
   - State "TOTEST"     from              [2023-09-06 水 13:49]
   :END:
指定したjsonファイルからindexを作成できる
*** TOTEST dump_index
   :LOGBOOK:
   - State "TOTEST"     from              [2023-09-06 水 13:50]
   :END:
現在のindexを指定したパスのファイルに保存できる。

*** TOTEST dump_footprint
    :LOGBOOK:
    - State "TOTEST"     from              [2023-09-06 水 21:54]
    :END:


* CRAWLERの構成
職能が描けたならば、構成を考えることができる。
構成を考える段に於いては、CRAWLERの職能を外界環境として、その他のクラスの責任を考えることができる。設計の基本原理は、この段になって初めて、継承やコンポジションによる抽象化を行うべきだ、ということだ。熟達した設計者ならば最初からこのような抽象化によって適切なアーキテクチャを設計することも可能だろうが、まずは原理に忠実に考えることが出来なければ話にならないし、熟達した設計者であっても基本に立ち返ることが重要になる場面は少なくないだろう。
#+begin_src plantuml :file static/img/crawler_activity.svg
start

partition "initialize" {
:ドメインのデータディレクトリを探す;
if (データディレクトリがある) then (yes)
:indexをロードする;
else (no)
:ドメインのhash名でディレクトリを作成する;
}

if (indexがある) then (yes)
:indexをロードする;
else (no)
:LPへ飛ぶ;
endif

#+end_src

#+RESULTS:
[[file:static/img/crawler_activity.svg]]

#+begin_src plantuml
main -> CRAWLER: initialize
activate CRAWLER


#+end_src



* PARSER
* EVALUATER
