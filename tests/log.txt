============================= test session starts ==============================
platform linux -- Python 3.11.3, pytest-7.4.0, pluggy-1.2.0
rootdir: /home/adelie/project/chex/tests
plugins: anyio-3.7.1
collected 13 items

test_core.py F.......FFFFF                                               [100%]

=================================== FAILURES ===================================
____________________________ TestCrawler.test_init _____________________________

self = <src.crawler.Crawler object at 0x7d96d9686e90>
file_path = '../tmp/8b6a9f089f36cbef133e9b29438e6f04579181c4/index.json'

    def load_json(self, file_path):
        try:
            with open(file_path, "r") as f:
                s = f.read()
>           data = json.loads(s)

../src/crawler.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../.local/pyenv/versions/3.11.3/lib/python3.11/json/__init__.py:346: in loads
    return _default_decoder.decode(s)
../../../.local/pyenv/versions/3.11.3/lib/python3.11/json/decoder.py:337: in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <json.decoder.JSONDecoder object at 0x7d96da468d50>, s = '', idx = 0

    def raw_decode(self, s, idx=0):
        """Decode a JSON document from ``s`` (a ``str`` beginning with
        a JSON document) and return a 2-tuple of the Python
        representation and the index in ``s`` where the document ended.
    
        This can be used to decode a JSON document from a string that may
        have extraneous data at the end.
    
        """
        try:
            obj, end = self.scan_once(s, idx)
        except StopIteration as err:
>           raise JSONDecodeError("Expecting value", s, err.value) from None
E           json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

../../../.local/pyenv/versions/3.11.3/lib/python3.11/json/decoder.py:355: JSONDecodeError

During handling of the above exception, another exception occurred:

self = <tests.test_core.TestCrawler object at 0x7d96d994da50>

    def test_init(self):
>       crawler = Crawler(domain)

test_core.py:25: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../src/crawler.py:119: in __init__
    self._init_index()
../src/crawler.py:187: in _init_index
    index = self.load_json(index_path)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.crawler.Crawler object at 0x7d96d9686e90>
file_path = '../tmp/8b6a9f089f36cbef133e9b29438e6f04579181c4/index.json'

    def load_json(self, file_path):
        try:
            with open(file_path, "r") as f:
                s = f.read()
            data = json.loads(s)
        except:
            data = None
>           raise ValueError(f"couldn't load json:{file_path}")
E           ValueError: couldn't load json:../tmp/8b6a9f089f36cbef133e9b29438e6f04579181c4/index.json

../src/crawler.py:336: ValueError
___________________________ TestCrawler.test_get_lp ____________________________

self = <src.crawler.Crawler object at 0x7d96d94aa210>
file_path = '../tmp/8b6a9f089f36cbef133e9b29438e6f04579181c4/index.json'

    def load_json(self, file_path):
        try:
            with open(file_path, "r") as f:
                s = f.read()
>           data = json.loads(s)

../src/crawler.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../.local/pyenv/versions/3.11.3/lib/python3.11/json/__init__.py:346: in loads
    return _default_decoder.decode(s)
../../../.local/pyenv/versions/3.11.3/lib/python3.11/json/decoder.py:337: in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <json.decoder.JSONDecoder object at 0x7d96da468d50>, s = '', idx = 0

    def raw_decode(self, s, idx=0):
        """Decode a JSON document from ``s`` (a ``str`` beginning with
        a JSON document) and return a 2-tuple of the Python
        representation and the index in ``s`` where the document ended.
    
        This can be used to decode a JSON document from a string that may
        have extraneous data at the end.
    
        """
        try:
            obj, end = self.scan_once(s, idx)
        except StopIteration as err:
>           raise JSONDecodeError("Expecting value", s, err.value) from None
E           json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

../../../.local/pyenv/versions/3.11.3/lib/python3.11/json/decoder.py:355: JSONDecodeError

During handling of the above exception, another exception occurred:

self = <tests.test_core.TestCrawler object at 0x7d96d966fc90>

    def test_get_lp(self):
>       crawler = Crawler(domain)

test_core.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../src/crawler.py:119: in __init__
    self._init_index()
../src/crawler.py:187: in _init_index
    index = self.load_json(index_path)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.crawler.Crawler object at 0x7d96d94aa210>
file_path = '../tmp/8b6a9f089f36cbef133e9b29438e6f04579181c4/index.json'

    def load_json(self, file_path):
        try:
            with open(file_path, "r") as f:
                s = f.read()
            data = json.loads(s)
        except:
            data = None
>           raise ValueError(f"couldn't load json:{file_path}")
E           ValueError: couldn't load json:../tmp/8b6a9f089f36cbef133e9b29438e6f04579181c4/index.json

../src/crawler.py:336: ValueError
___________________________ TestCrawler.test_get_res ___________________________

self = <src.crawler.Crawler object at 0x7d96d946d4d0>
file_path = '../tmp/8b6a9f089f36cbef133e9b29438e6f04579181c4/index.json'

    def load_json(self, file_path):
        try:
            with open(file_path, "r") as f:
                s = f.read()
>           data = json.loads(s)

../src/crawler.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../.local/pyenv/versions/3.11.3/lib/python3.11/json/__init__.py:346: in loads
    return _default_decoder.decode(s)
../../../.local/pyenv/versions/3.11.3/lib/python3.11/json/decoder.py:337: in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <json.decoder.JSONDecoder object at 0x7d96da468d50>, s = '', idx = 0

    def raw_decode(self, s, idx=0):
        """Decode a JSON document from ``s`` (a ``str`` beginning with
        a JSON document) and return a 2-tuple of the Python
        representation and the index in ``s`` where the document ended.
    
        This can be used to decode a JSON document from a string that may
        have extraneous data at the end.
    
        """
        try:
            obj, end = self.scan_once(s, idx)
        except StopIteration as err:
>           raise JSONDecodeError("Expecting value", s, err.value) from None
E           json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

../../../.local/pyenv/versions/3.11.3/lib/python3.11/json/decoder.py:355: JSONDecodeError

During handling of the above exception, another exception occurred:

self = <tests.test_core.TestCrawler object at 0x7d96d9684310>

    def test_get_res(self):
>       crawler = Crawler(domain)

test_core.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../src/crawler.py:119: in __init__
    self._init_index()
../src/crawler.py:187: in _init_index
    index = self.load_json(index_path)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.crawler.Crawler object at 0x7d96d946d4d0>
file_path = '../tmp/8b6a9f089f36cbef133e9b29438e6f04579181c4/index.json'

    def load_json(self, file_path):
        try:
            with open(file_path, "r") as f:
                s = f.read()
            data = json.loads(s)
        except:
            data = None
>           raise ValueError(f"couldn't load json:{file_path}")
E           ValueError: couldn't load json:../tmp/8b6a9f089f36cbef133e9b29438e6f04579181c4/index.json

../src/crawler.py:336: ValueError
____________________________ TestCrawler.test_load _____________________________

self = <src.crawler.Crawler object at 0x7d96d942fd90>
file_path = '../tmp/8b6a9f089f36cbef133e9b29438e6f04579181c4/index.json'

    def load_json(self, file_path):
        try:
            with open(file_path, "r") as f:
                s = f.read()
>           data = json.loads(s)

../src/crawler.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../.local/pyenv/versions/3.11.3/lib/python3.11/json/__init__.py:346: in loads
    return _default_decoder.decode(s)
../../../.local/pyenv/versions/3.11.3/lib/python3.11/json/decoder.py:337: in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <json.decoder.JSONDecoder object at 0x7d96da468d50>, s = '', idx = 0

    def raw_decode(self, s, idx=0):
        """Decode a JSON document from ``s`` (a ``str`` beginning with
        a JSON document) and return a 2-tuple of the Python
        representation and the index in ``s`` where the document ended.
    
        This can be used to decode a JSON document from a string that may
        have extraneous data at the end.
    
        """
        try:
            obj, end = self.scan_once(s, idx)
        except StopIteration as err:
>           raise JSONDecodeError("Expecting value", s, err.value) from None
E           json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

../../../.local/pyenv/versions/3.11.3/lib/python3.11/json/decoder.py:355: JSONDecodeError

During handling of the above exception, another exception occurred:

self = <tests.test_core.TestCrawler object at 0x7d96d9684990>

    def test_load(self):
>       crawler = Crawler(domain)

test_core.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../src/crawler.py:119: in __init__
    self._init_index()
../src/crawler.py:187: in _init_index
    index = self.load_json(index_path)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.crawler.Crawler object at 0x7d96d942fd90>
file_path = '../tmp/8b6a9f089f36cbef133e9b29438e6f04579181c4/index.json'

    def load_json(self, file_path):
        try:
            with open(file_path, "r") as f:
                s = f.read()
            data = json.loads(s)
        except:
            data = None
>           raise ValueError(f"couldn't load json:{file_path}")
E           ValueError: couldn't load json:../tmp/8b6a9f089f36cbef133e9b29438e6f04579181c4/index.json

../src/crawler.py:336: ValueError
______________________ TestCrawler.test_get_json_from_res ______________________

self = <src.crawler.Crawler object at 0x7d96d946c050>
file_path = '../tmp/8b6a9f089f36cbef133e9b29438e6f04579181c4/index.json'

    def load_json(self, file_path):
        try:
            with open(file_path, "r") as f:
                s = f.read()
>           data = json.loads(s)

../src/crawler.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../.local/pyenv/versions/3.11.3/lib/python3.11/json/__init__.py:346: in loads
    return _default_decoder.decode(s)
../../../.local/pyenv/versions/3.11.3/lib/python3.11/json/decoder.py:337: in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <json.decoder.JSONDecoder object at 0x7d96da468d50>, s = '', idx = 0

    def raw_decode(self, s, idx=0):
        """Decode a JSON document from ``s`` (a ``str`` beginning with
        a JSON document) and return a 2-tuple of the Python
        representation and the index in ``s`` where the document ended.
    
        This can be used to decode a JSON document from a string that may
        have extraneous data at the end.
    
        """
        try:
            obj, end = self.scan_once(s, idx)
        except StopIteration as err:
>           raise JSONDecodeError("Expecting value", s, err.value) from None
E           json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

../../../.local/pyenv/versions/3.11.3/lib/python3.11/json/decoder.py:355: JSONDecodeError

During handling of the above exception, another exception occurred:

self = <tests.test_core.TestCrawler object at 0x7d96d9685010>

    def test_get_json_from_res(self):
>       crawler = Crawler(domain)

test_core.py:75: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../src/crawler.py:119: in __init__
    self._init_index()
../src/crawler.py:187: in _init_index
    index = self.load_json(index_path)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.crawler.Crawler object at 0x7d96d946c050>
file_path = '../tmp/8b6a9f089f36cbef133e9b29438e6f04579181c4/index.json'

    def load_json(self, file_path):
        try:
            with open(file_path, "r") as f:
                s = f.read()
            data = json.loads(s)
        except:
            data = None
>           raise ValueError(f"couldn't load json:{file_path}")
E           ValueError: couldn't load json:../tmp/8b6a9f089f36cbef133e9b29438e6f04579181c4/index.json

../src/crawler.py:336: ValueError
__________________________ TestCrawler.test_crawling ___________________________

self = <src.crawler.Crawler object at 0x7d96d9b0af10>
file_path = '../tmp/8b6a9f089f36cbef133e9b29438e6f04579181c4/index.json'

    def load_json(self, file_path):
        try:
            with open(file_path, "r") as f:
                s = f.read()
>           data = json.loads(s)

../src/crawler.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../.local/pyenv/versions/3.11.3/lib/python3.11/json/__init__.py:346: in loads
    return _default_decoder.decode(s)
../../../.local/pyenv/versions/3.11.3/lib/python3.11/json/decoder.py:337: in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <json.decoder.JSONDecoder object at 0x7d96da468d50>, s = '', idx = 0

    def raw_decode(self, s, idx=0):
        """Decode a JSON document from ``s`` (a ``str`` beginning with
        a JSON document) and return a 2-tuple of the Python
        representation and the index in ``s`` where the document ended.
    
        This can be used to decode a JSON document from a string that may
        have extraneous data at the end.
    
        """
        try:
            obj, end = self.scan_once(s, idx)
        except StopIteration as err:
>           raise JSONDecodeError("Expecting value", s, err.value) from None
E           json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

../../../.local/pyenv/versions/3.11.3/lib/python3.11/json/decoder.py:355: JSONDecodeError

During handling of the above exception, another exception occurred:

self = <tests.test_core.TestCrawler object at 0x7d96d9685690>

    def test_crawling(self):
>       crawler = Crawler(domain)

test_core.py:81: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../src/crawler.py:119: in __init__
    self._init_index()
../src/crawler.py:187: in _init_index
    index = self.load_json(index_path)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.crawler.Crawler object at 0x7d96d9b0af10>
file_path = '../tmp/8b6a9f089f36cbef133e9b29438e6f04579181c4/index.json'

    def load_json(self, file_path):
        try:
            with open(file_path, "r") as f:
                s = f.read()
            data = json.loads(s)
        except:
            data = None
>           raise ValueError(f"couldn't load json:{file_path}")
E           ValueError: couldn't load json:../tmp/8b6a9f089f36cbef133e9b29438e6f04579181c4/index.json

../src/crawler.py:336: ValueError
=========================== short test summary info ============================
FAILED test_core.py::TestCrawler::test_init - ValueError: couldn't load json:...
FAILED test_core.py::TestCrawler::test_get_lp - ValueError: couldn't load jso...
FAILED test_core.py::TestCrawler::test_get_res - ValueError: couldn't load js...
FAILED test_core.py::TestCrawler::test_load - ValueError: couldn't load json:...
FAILED test_core.py::TestCrawler::test_get_json_from_res - ValueError: couldn...
FAILED test_core.py::TestCrawler::test_crawling - ValueError: couldn't load j...
========================= 6 failed, 7 passed in 0.33s ==========================
